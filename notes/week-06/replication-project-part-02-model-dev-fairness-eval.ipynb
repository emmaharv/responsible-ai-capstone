{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9395c475",
   "metadata": {},
   "source": [
    "## DSC 180AB Data Science Capstone\n",
    "### Replication Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e49e865",
   "metadata": {},
   "source": [
    "Team Members:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa1c3d2",
   "metadata": {},
   "source": [
    "### Table of Contents\n",
    "To return to the table of contents, click on the number at any major section heading."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dacfbb4",
   "metadata": {
    "tags": []
   },
   "source": [
    "[1. Introduction](#1.-Introduction)\n",
    "\n",
    "[2. Exploratory Data Analysis](#2.-Exploratory-Data-Analysis)\n",
    "\n",
    "[3. Model Development](#3.-Model-Development)\n",
    "\n",
    "[4. Model Evaluation](#4.-Model-Evaluation)\n",
    "\n",
    "[5. Bias Mitigation](#5.-Bias-Mitigation)\n",
    "\n",
    "[6. Results Summary](#6.-Results-Summary)\n",
    "\n",
    "[7. Explainability](#7.-Explainability)\n",
    "\n",
    "[8. Conclusion & Discussion](#8.-Conclusion-&-Discussion)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76354145-7d96-4a89-92ec-4dfa713ff959",
   "metadata": {
    "tags": []
   },
   "source": [
    "## This tutorial demonstrates classification model learning with bias mitigation as a part of a Care Management use case using Medical Expenditure data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7799d7d3-7572-4e08-9e3a-812ba39befda",
   "metadata": {},
   "source": [
    "The notebook demonstrates how the AIF 360 toolkit can be used to detect and reduce bias when learning classifiers using a variety of fairness metrics and algorithms . It also demonstrates how explanations can be generated for predictions made by models learnt with the toolkit using LIME.\n",
    "\n",
    "* Classifiers are built using Logistic Regression as well as Random Forests.\n",
    "* Bias detection is demonstrated using several metrics, including disparate impact, average odds difference, statistical parity difference, equal opportunity difference, and Theil index.\n",
    "* Bias alleviation is explored via a variety of methods, including reweighing (pre-processing algorithm), prejudice remover (in-processing algorithm), and disparate impact remover (pre-processing technique).\n",
    "* Data from the [Medical Expenditure Panel Survey](https://meps.ahrq.gov/mepsweb/) is used in this tutorial.\n",
    "\n",
    "\n",
    "The Medical Expenditure Panel Survey (MEPS) provides nationally representative estimates of health expenditure, utilization, payment sources, health status, and health insurance coverage among the noninstitutionalized U.S. population. These government-produced data sets examine how people use the US healthcare system.\n",
    "\n",
    "MEPS is administered by the Agency for Healthcare Research and Quality (AHRQ) and is divided into three components: \n",
    "* Household\n",
    "* Insurance/Employer, and \n",
    "* Medical Provider. \n",
    "\n",
    "These components provide comprehensive national estimates of health care use and payment by individuals, families, and any other demographic group of interest."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebad3269",
   "metadata": {},
   "source": [
    "### [1.](#Table-of-Contents) Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c682f615",
   "metadata": {},
   "source": [
    "The [AI Fairness 360 toolkit](https://github.com/Trusted-AI/AIF360) is an extensible open-source library containing techniques developed by the research community to help detect and mitigate bias in machine learning models throughout the AI application lifecycle. AI Fairness 360 package is available in both Python and R. Documentation is available [here](https://aif360.readthedocs.io/en/v0.2.3/index.html)\n",
    "\n",
    "The AI Fairness 360 package includes: \n",
    "- a comprehensive set of metrics for datasets and models to test for biases,\n",
    "- explanations for these metrics, and\n",
    "- algorithms to mitigate bias in datasets and models\n",
    "It is designed to translate algorithmic research from the lab into the actual practice of domains as wide-ranging as finance, human capital management, healthcare, and education"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "523227a6-425b-4dba-bb8a-81ea10e59102",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 1.1 Use Case\n",
    "\n",
    "**In order to demonstrate how AIF360 can be used to detect and mitigate bias in classfier models, we adopt the following use case:**\n",
    "\n",
    "* Data scientist develops a 'fair' healthcare utilization scoring model with respect to defined protected classes. Fairness may be dictated by legal or government regulations, such as a requirement that additional care decisions be not predicated on factors such as race of the patient.\n",
    "* Developer takes the model AND performance characteristics / specs of the model (e.g. accuracy, fairness tests, etc. basically the model factsheet) and deploys the model in an enterprise app that prioritizes cases for care management.\n",
    "* The app is put into production and starts scoring people and making recommendations. \n",
    "* Explanations are generated for each recommendation\n",
    "* Both recommendations and associated explanations are given to nurses as a part of the care management process. The nurses can evaluate the recommendations for quality and correctness and provide feedback.\n",
    "* Nurse feedback as well as analysis of usage data with respect to specs of the model w.r.t accuracy and fairness is communicated to AI Ops specialist and LOB user periodically.\n",
    "* When significant drift in model specs relative to the model factsheet is observed, the model is sent back for retraining."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b3fccd-dada-42d4-a408-42582b8d060f",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 1.2 Data\n",
    "Released as an ASCII file (with related SAS, SPSS, and STATA programming statements) and a SAS transport dataset, this public use file provides information collected on a nationally representative sample of the civilian noninstitutionalized population of the United States for calendar year 2015. This file consists of MEPS survey data obtained in Rounds 3, 4, and 5 of Panel 19 and Rounds 1, 2, and 3 of Panel 20 (i.e., the rounds for the MEPS panels covering calendar year 2015) and consolidates all of the final 2015 person-level variables onto one file. This file contains the following variables previously released on HC-174: survey administration, language of interview variable, demographics, parent identifiers, health status, disability days variables, access to care, employment, quality of care, patient satisfaction, health insurance, and use variables. The HC-181 file also includes these variables: income variables and expenditure variables.\n",
    "\n",
    "The specific data used is the [2015 Full Year Consolidated Data File](https://meps.ahrq.gov/mepsweb/data_stats/download_data_files_detail.jsp?cboPufNumber=HC-181) as well as the [2016 Full Year Consolidated Data File](https://meps.ahrq.gov/mepsweb/data_stats/download_data_files_detail.jsp?cboPufNumber=HC-192).\n",
    "\n",
    "* The 2015 file contains data from rounds 3,4,5 of panel 19 (2014) and rounds 1,2,3 of panel 20 (2015). \n",
    "* The 2016 file contains data from rounds 3,4,5 of panel 20 (2015) and rounds 1,2,3 of panel 21 (2016).\n",
    "\n",
    "In this example, three datasets were constructed: one from panel 19, round 5 (used for learning models), one from panel 20, round 3 (used for deployment/testing of model - steps); the other from panel 21, round 3 (used for re-training and deployment/testing of updated model)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bcd0b66-89d3-4e62-a3af-1b62b3dbaf27",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### 1.3 Methodology \n",
    "\n",
    "For each dataset, the sensitive attribute is 'RACE' constructed as follows: 'Whites' (privileged class) defined by the features RACEV2X = 1 (White) and HISPANX = 2 (non Hispanic); 'Non-Whites' that included everyone else.  \n",
    "\n",
    "* Along with race as the sensitive feature, other features used for modeling include demographics  (such as age, gender, active duty status), physical/mental health assessments, diagnosis codes (such as history of diagnosis of cancer, or diabetes), and limitations (such as cognitive or hearing or vision limitation).\n",
    "* To measure utilization, a composite feature, 'UTILIZATION', was created to measure the total number of trips requiring some sort of medical care by summing up the following features: OBTOTV15(16), the number of office based visits;  OPTOTV15(16), the number of outpatient visits; ERTOT15(16), the number of ER visits;  IPNGTD15(16), the number of inpatient nights, and  + HHTOTD16, the number of home health visits.\n",
    "* The model classification task is to predict whether a person would have 'high' utilization (defined as UTILIZATION >= 10, roughly the average utilization for the considered population). High utilization respondents constituted around 17% of each dataset.\n",
    "* To simulate the scenario, each dataset is split into 3 parts: a train, a validation, and a test/deployment part.\n",
    "\n",
    "**We assume that the model is initially built and tuned using the 2015 Panel 19 train/test data**\n",
    "* It is then put into practice and used to score people to identify potential candidates for care management. \n",
    "* Initial deployment is simulated to 2015 Panel 20 deployment data. \n",
    "* To show change in performance and/or fairness over time, the 2016 Panel 21 deployment data is used. \n",
    "* Finally, if drift is observed, the 2015 train/validation data is used to learn a new model and evaluated again on the 2016 deployment data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "913a44da",
   "metadata": {},
   "source": [
    "### 1.4 Insert writeup of overall replication project goals and big picture thinking (2-3 paragraphs).  \n",
    "* Why do we care about this? \n",
    "* What would the benefit of predicting utilization be? \n",
    "* What might occur if there are errors?\n",
    "* Who are the affected parties and stakeholders?\n",
    "* Other thoughts?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd7569b-9388-4939-9422-6d134dbc0303",
   "metadata": {},
   "source": [
    "**Write up here:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f776c5-8ed6-49c3-9f12-f2afed0605d4",
   "metadata": {},
   "source": [
    "---\n",
    "End of Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f1413d0",
   "metadata": {},
   "source": [
    "### [2.](#Table-of-Contents) Exploratory Data Analysis (EDA)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c4a57f-abcf-47c6-961e-baec728e930a",
   "metadata": {},
   "source": [
    "The specific data used is the [2015 Full Year Consolidated Data File](https://meps.ahrq.gov/mepsweb/data_stats/download_data_files_detail.jsp?cboPufNumber=HC-181) as well as the [2016 Full Year Consolidated Data File](https://meps.ahrq.gov/mepsweb/data_stats/download_data_files_detail.jsp?cboPufNumber=HC-192).\n",
    "\n",
    "* The 2015 file contains data from rounds 3,4,5 of panel 19 (2014) and rounds 1,2,3 of panel 20 (2015). \n",
    "* The 2016 file contains data from rounds 3,4,5 of panel 20 (2015) and rounds 1,2,3 of panel 21 (2016).\n",
    "\n",
    "In this example, three datasets were constructed: one from panel 19, round 5 (used for learning models), one from panel 20, round 3 (used for deployment/testing of model - steps); the other from panel 21, round 3 (used for re-training and deployment/testing of updated model).\n",
    "\n",
    "See the corresponding [Codebook](https://meps.ahrq.gov/mepsweb/data_stats/download_data_files_detail.jsp?cboPufNumber=HC-181) for information on variables.\n",
    "\n",
    "##### Key MEPS dataset features include:\n",
    "* **Utilization**: To measure utilization, a composite feature, 'UTILIZATION', was created to measure the total number of trips requiring some sort of medical care by summing up the following features: OBTOTV15(16), the number of office based visits;  OPTOTV15(16), the number of outpatient visits; ERTOT15(16), the number of ER visits;  IPNGTD15(16), the number of inpatient nights, and  + HHTOTD16, the number of home health visits.\n",
    "* The model classification task is to predict whether a person would have **'high'** utilization (defined as UTILIZATION >= 10, roughly the average utilization for the considered population). High utilization respondents constituted around 17% of each dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7368b94-7451-4cf1-8a66-229d2a07907d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### 2.0 Pre-processing Scripts (for each Panel)\n",
    "\n",
    "There is currently minimal EDA for this tutorial within IBM AIF360 Medical Expenditure Tutorial. Therefore, we have adapted  utility scripts from IBM AIF360 Tutorial for ease of understanding for how datasets were pre-processed. These will be used primarily for EDA purposes. We will utilize IBM's tutorial for the remainder of the project. We have utilized Pandas for this portion of the project. \n",
    "\n",
    "**Note:** these pre-processing script below are run for each data file, and then filtered for each panel. This was done in order to match subsequent portions of the tutorial, and how train/test/validation datasets were split."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b833fd",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 2.1 Get and Load Dataset, Apply Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd36982c-27bb-4159-9d99-1730c1ca8b6c",
   "metadata": {
    "tags": []
   },
   "source": [
    "**Before Proceeding Ensure You Have:**\n",
    "* Forked the AIF360 R=repository and cloned locally to your disk or virtual machine\n",
    "* Downloaded the `h181.csv` and `h192.csv` data files uploaded [here](https://www.kaggle.com/datasets/nanrahman/mepsdata)\n",
    "* Place the `h181.csv` and `h192.csv` in a folder you can access (we placed it in `../aif360/data/raw/meps/` of our forked AIF360 repository)\n",
    "* For EDA we only focus on `h181.csv` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b887ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import sys\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from IPython.display import Markdown, display\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# Datasets\n",
    "from aif360.datasets import MEPSDataset19\n",
    "from aif360.datasets import MEPSDataset20\n",
    "from aif360.datasets import MEPSDataset21\n",
    "\n",
    "# Fairness metrics\n",
    "from aif360.metrics import BinaryLabelDatasetMetric\n",
    "from aif360.metrics import ClassificationMetric\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90379749-ae30-4908-b400-400254239ecd",
   "metadata": {
    "tags": []
   },
   "source": [
    " ### REPLACE THIS SECTION WITH YOUR PREVIOUS EDA ANALYSIS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89cb0cec-6f20-4201-bdaa-feb032b62411",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "### End of Replication Part 01 -  EDA\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef7f4e6-b2f0-4c7c-ab1f-9094a6339865",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "-----\n",
    "# Start of Replication Part 02 -  Model Development, and Fairness Evaluation\n",
    "\n",
    "## There are **two** components to `Replication Project Part #02`\n",
    "1. Training models without de-biasing, using IBM's tutorial\n",
    "2. Training models without de-biasing, using your own model development techniques including (1) Feature Selection, (2) Encoding, (3) Binning Features, and other items \n",
    "\n",
    "#### We will now return to IBM AIF360's [Medical Expenditure Tutorial](https://nbviewer.org/github/IBM/AIF360/blob/master/examples/tutorial_medical_expenditure.ipynb) \n",
    "_*Note that it is primarily Scikit-learn based_\n",
    "\n",
    "* A reminder, you will need to fork [AIF360's repository](https://github.com/Trusted-AI/AIF360) into your own GitHub and access the notebook locally or via your method of choice\n",
    "* AIF360's Repository can be found under: `AIF360`/`Examples`/tutorial_medical_expenditure.ipynb\n",
    "* Ensure you have your `aif360` environment turned and activated using a miniconda prompt\n",
    "* Use Jupyter Labs\n",
    "* Refer to [Week 03](https://nanrahman.github.io/capstone-responsible-ai/weeks/03-Replication-Part-00/) content on the course Website to access the `Quickstart Guide`\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5550894e-d038-45ae-aea8-fbbcdf9e1b09",
   "metadata": {
    "tags": []
   },
   "source": [
    "### [3.](#Table-of-Contents) Model Development without Debiasing \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b80716-116d-4a6f-b3ab-d74ed6becb20",
   "metadata": {},
   "source": [
    "First, load all necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bddca008-8041-47b5-915e-3df884b48823",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../')\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "# Datasets\n",
    "from aif360.datasets import MEPSDataset19\n",
    "from aif360.datasets import MEPSDataset20\n",
    "from aif360.datasets import MEPSDataset21\n",
    "\n",
    "# Fairness metrics\n",
    "from aif360.metrics import BinaryLabelDatasetMetric\n",
    "from aif360.metrics import ClassificationMetric\n",
    "\n",
    "# Explainers\n",
    "from aif360.explainers import MetricTextExplainer\n",
    "\n",
    "# Scalers\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Classifiers\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# Bias mitigation techniques\n",
    "from aif360.algorithms.preprocessing import Reweighing\n",
    "from aif360.algorithms.inprocessing import PrejudiceRemover\n",
    "\n",
    "# LIME\n",
    "from aif360.datasets.lime_encoder import LimeEncoder\n",
    "import lime\n",
    "from lime.lime_tabular import LimeTabularExplainer\n",
    "\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c80809-7254-49b7-8cce-0adfdee9a135",
   "metadata": {},
   "source": [
    "### 3.1. Load data & create splits for learning/validating/testing model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a94295-27c2-482c-966f-751714b61e7e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 3.2. Learning a Logistic Regression (LR) classifier on original data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22318c2a-8698-4430-9670-41366dd9a39e",
   "metadata": {},
   "source": [
    "### 3.3. Learning a Random Forest (RF) classifier on original data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "780381f0-6341-4b13-901e-112e156b829b",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Section 3 Write Up here\n",
    "\n",
    "### Part-01: For **both** the logistic regression and random forest classifiers learned on the original data, please include explain the results of your fairness metrics. For _each_ metric result briefly describe what this value means in 1-2 sentences (is it fair, is it not fair? Why?)\n",
    "\n",
    "**Fairness Metric Summary** \n",
    "* Threshold corresponding to Best balanced accuracy:\n",
    "* Best balanced accuracy: \n",
    "* Corresponding 1-min(DI, 1/DI) value: \n",
    "* Corresponding average odds difference value: \n",
    "* Corresponding statistical parity difference value: \n",
    "* Corresponding equal opportunity difference value:\n",
    "* Corresponding Theil index value:\n",
    "\n",
    "### Part-02: Please write one paragraph for each question.\n",
    "1. How can we determine which metrics to use, given our data and use case? You can refer to [Course material](https://nanrahman.github.io/capstone-responsible-ai/weeks/06-Fairness-Assessments/), online research and Guidance provided by [AIF360](http://aif360.mybluemix.net/resources#)\n",
    "2. When you have competing fairness metrics, how to pick which to prioritize?\n",
    "3. What do you do when you encounter different definitions for similar metrics?\n",
    "4. Based on this, which model and fairness metric appears the best to proceed with?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d53682fc-9332-498f-abe9-209744d7cbbd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### [4.](#Table-of-Contents) Additional Model Development\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de965d1e-5cf4-45f6-84e5-4b5a5caf34c2",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 4.1A Load data & create splits for learning/validating/testing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "970834e3-01eb-46e2-a026-3a1fb1a19533",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the same methods from Section 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae16fc0-16de-49ab-bb8a-70a1d58cc4ab",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 4.1B Utilize findings from your EDA to complete any additional mmodel development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf86f7a-1a16-4383-a3ee-544337442742",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examples:\n",
    "\n",
    "# Feature selection \n",
    "# encoding\n",
    "# binning categorical features\n",
    "\n",
    "# Feel free to use the codebook from MEPS to explore other variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22345104-7e28-43c0-af32-efffcf8b4920",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 4.2. Learning a Logistic Regression (LR) classifier on original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1547e0f-a23a-4bbf-82a8-107bab7ac739",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the same methods from Section 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da8258f9-430f-4569-bb8c-f7a1ca1580ef",
   "metadata": {},
   "source": [
    "### 4.3. Learning a Random Forest (RF) classifier on original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d228c01c-6058-4706-9179-206629a8e800",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the same methods from Section 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc612147-c6ab-4aea-a37f-95f44363cf90",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Section 4 Write Up here\n",
    "\n",
    "**1. For both the logistic regression and random forest classifiers learned on the original data, please include the results of your fairness metrics. For _each_ metric result briefly describe (1-2 sentences) if you saw any differences from your results in Part 3, and what that might mean.**\n",
    "\n",
    "_Fairness Metrics_\n",
    "   * Threshold corresponding to Best balanced accuracy:\n",
    "   * Best balanced accuracy: \n",
    "   * Corresponding 1-min(DI, 1/DI) value: \n",
    "   * Corresponding average odds difference value: \n",
    "   * Corresponding statistical parity difference value: \n",
    "   * Corresponding equal opportunity difference value:\n",
    "   * Corresponding Theil index value:\n",
    "    \n",
    "**2. Based on this, would you make any recommendations during model development? Does it change which model and fairness metric would be the best to proceed with?** (Please write at least one paragraph)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99473a5c-2910-4c77-a53a-f0022871225d",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "### End of Replication Part 02 -  Model Development and Fairness Evaluation\n",
    "\n",
    "----\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdad4c69-65f4-4646-87a2-996c8f983447",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### _Items below will be updated as course progress_\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b3e294",
   "metadata": {},
   "source": [
    "### [5.](#Table-of-Contents) Bias Mitigation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "106d7b57",
   "metadata": {},
   "source": [
    "### [6.](#Table-of-Contents) Results Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61997b93",
   "metadata": {},
   "source": [
    "### [7.](#Table-of-Contents) Explainability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9010ecc",
   "metadata": {},
   "source": [
    "### [8.](#Table-of-Contents) Conclusion & Discussion"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc-autonumbering": false,
  "toc-showcode": true,
  "toc-showmarkdowntxt": true,
  "toc-showtags": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
