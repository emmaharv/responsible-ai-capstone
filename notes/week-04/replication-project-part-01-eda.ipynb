{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9395c475",
   "metadata": {},
   "source": [
    "## DSC 180AB Data Science Capstone\n",
    "### Replication Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e49e865",
   "metadata": {},
   "source": [
    "Team Members:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa1c3d2",
   "metadata": {},
   "source": [
    "### Table of Contents\n",
    "To return to the table of contents, click on the number at any major section heading."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dacfbb4",
   "metadata": {},
   "source": [
    "[1. Introduction](#1.-Introduction)\n",
    "\n",
    "[2. Exploratory Data Analysis](#2.-Exploratory-Data-Analysis)\n",
    "\n",
    "[3. Model Development](#3.-Model-Development)\n",
    "\n",
    "[4. Model Evaluation](#4.-Model-Evaluation)\n",
    "\n",
    "[5. Bias Mitigation](#5.-Bias-Mitigation)\n",
    "\n",
    "[6. Results Summary](#6.-Results-Summary)\n",
    "\n",
    "[7. Explainability](#7.-Explainability)\n",
    "\n",
    "[8. Conclusion & Discussion](#8.-Conclusion-&-Discussion)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76354145-7d96-4a89-92ec-4dfa713ff959",
   "metadata": {},
   "source": [
    "## This tutorial demonstrates classification model learning with bias mitigation as a part of a Care Management use case using Medical Expenditure data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7799d7d3-7572-4e08-9e3a-812ba39befda",
   "metadata": {},
   "source": [
    "The notebook demonstrates how the AIF 360 toolkit can be used to detect and reduce bias when learning classifiers using a variety of fairness metrics and algorithms . It also demonstrates how explanations can be generated for predictions made by models learnt with the toolkit using LIME.\n",
    "\n",
    "* Classifiers are built using Logistic Regression as well as Random Forests.\n",
    "* Bias detection is demonstrated using several metrics, including disparate impact, average odds difference, statistical parity difference, equal opportunity difference, and Theil index.\n",
    "* Bias alleviation is explored via a variety of methods, including reweighing (pre-processing algorithm), prejudice remover (in-processing algorithm), and disparate impact remover (pre-processing technique).\n",
    "* Data from the [Medical Expenditure Panel Survey](https://meps.ahrq.gov/mepsweb/) is used in this tutorial.\n",
    "\n",
    "\n",
    "The Medical Expenditure Panel Survey (MEPS) provides nationally representative estimates of health expenditure, utilization, payment sources, health status, and health insurance coverage among the noninstitutionalized U.S. population. These government-produced data sets examine how people use the US healthcare system.\n",
    "\n",
    "MEPS is administered by the Agency for Healthcare Research and Quality (AHRQ) and is divided into three components: \n",
    "* Household\n",
    "* Insurance/Employer, and \n",
    "* Medical Provider. \n",
    "\n",
    "These components provide comprehensive national estimates of health care use and payment by individuals, families, and any other demographic group of interest."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebad3269",
   "metadata": {},
   "source": [
    "### [1.](#Table-of-Contents) Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c682f615",
   "metadata": {},
   "source": [
    "The [AI Fairness 360 toolkit](https://github.com/Trusted-AI/AIF360) is an extensible open-source library containing techniques developed by the research community to help detect and mitigate bias in machine learning models throughout the AI application lifecycle. AI Fairness 360 package is available in both Python and R. Documentation is available [here](https://aif360.readthedocs.io/en/v0.2.3/index.html)\n",
    "\n",
    "The AI Fairness 360 package includes: \n",
    "- a comprehensive set of metrics for datasets and models to test for biases,\n",
    "- explanations for these metrics, and\n",
    "- algorithms to mitigate bias in datasets and models\n",
    "It is designed to translate algorithmic research from the lab into the actual practice of domains as wide-ranging as finance, human capital management, healthcare, and education"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "523227a6-425b-4dba-bb8a-81ea10e59102",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 1.1 Use Case\n",
    "\n",
    "**In order to demonstrate how AIF360 can be used to detect and mitigate bias in classfier models, we adopt the following use case:**\n",
    "\n",
    "* Data scientist develops a 'fair' healthcare utilization scoring model with respect to defined protected classes. Fairness may be dictated by legal or government regulations, such as a requirement that additional care decisions be not predicated on factors such as race of the patient.\n",
    "* Developer takes the model AND performance characteristics / specs of the model (e.g. accuracy, fairness tests, etc. basically the model factsheet) and deploys the model in an enterprise app that prioritizes cases for care management.\n",
    "* The app is put into production and starts scoring people and making recommendations. \n",
    "* Explanations are generated for each recommendation\n",
    "* Both recommendations and associated explanations are given to nurses as a part of the care management process. The nurses can evaluate the recommendations for quality and correctness and provide feedback.\n",
    "* Nurse feedback as well as analysis of usage data with respect to specs of the model w.r.t accuracy and fairness is communicated to AI Ops specialist and LOB user periodically.\n",
    "* When significant drift in model specs relative to the model factsheet is observed, the model is sent back for retraining."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b3fccd-dada-42d4-a408-42582b8d060f",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 1.2 Data\n",
    "Released as an ASCII file (with related SAS, SPSS, and STATA programming statements) and a SAS transport dataset, this public use file provides information collected on a nationally representative sample of the civilian noninstitutionalized population of the United States for calendar year 2015. This file consists of MEPS survey data obtained in Rounds 3, 4, and 5 of Panel 19 and Rounds 1, 2, and 3 of Panel 20 (i.e., the rounds for the MEPS panels covering calendar year 2015) and consolidates all of the final 2015 person-level variables onto one file. This file contains the following variables previously released on HC-174: survey administration, language of interview variable, demographics, parent identifiers, health status, disability days variables, access to care, employment, quality of care, patient satisfaction, health insurance, and use variables. The HC-181 file also includes these variables: income variables and expenditure variables.\n",
    "\n",
    "The specific data used is the [2015 Full Year Consolidated Data File](https://meps.ahrq.gov/mepsweb/data_stats/download_data_files_detail.jsp?cboPufNumber=HC-181) as well as the [2016 Full Year Consolidated Data File](https://meps.ahrq.gov/mepsweb/data_stats/download_data_files_detail.jsp?cboPufNumber=HC-192).\n",
    "\n",
    "* The 2015 file contains data from rounds 3,4,5 of panel 19 (2014) and rounds 1,2,3 of panel 20 (2015). \n",
    "* The 2016 file contains data from rounds 3,4,5 of panel 20 (2015) and rounds 1,2,3 of panel 21 (2016).\n",
    "\n",
    "In this example, three datasets were constructed: one from panel 19, round 5 (used for learning models), one from panel 20, round 3 (used for deployment/testing of model - steps); the other from panel 21, round 3 (used for re-training and deployment/testing of updated model)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bcd0b66-89d3-4e62-a3af-1b62b3dbaf27",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### 1.3 Methodology \n",
    "\n",
    "For each dataset, the sensitive attribute is 'RACE' constructed as follows: 'Whites' (privileged class) defined by the features RACEV2X = 1 (White) and HISPANX = 2 (non Hispanic); 'Non-Whites' that included everyone else.  \n",
    "\n",
    "* Along with race as the sensitive feature, other features used for modeling include demographics  (such as age, gender, active duty status), physical/mental health assessments, diagnosis codes (such as history of diagnosis of cancer, or diabetes), and limitations (such as cognitive or hearing or vision limitation).\n",
    "* To measure utilization, a composite feature, 'UTILIZATION', was created to measure the total number of trips requiring some sort of medical care by summing up the following features: OBTOTV15(16), the number of office based visits;  OPTOTV15(16), the number of outpatient visits; ERTOT15(16), the number of ER visits;  IPNGTD15(16), the number of inpatient nights, and  + HHTOTD16, the number of home health visits.\n",
    "* The model classification task is to predict whether a person would have 'high' utilization (defined as UTILIZATION >= 10, roughly the average utilization for the considered population). High utilization respondents constituted around 17% of each dataset.\n",
    "* To simulate the scenario, each dataset is split into 3 parts: a train, a validation, and a test/deployment part.\n",
    "\n",
    "**We assume that the model is initially built and tuned using the 2015 Panel 19 train/test data**\n",
    "* It is then put into practice and used to score people to identify potential candidates for care management. \n",
    "* Initial deployment is simulated to 2015 Panel 20 deployment data. \n",
    "* To show change in performance and/or fairness over time, the 2016 Panel 21 deployment data is used. \n",
    "* Finally, if drift is observed, the 2015 train/validation data is used to learn a new model and evaluated again on the 2016 deployment data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "913a44da",
   "metadata": {},
   "source": [
    "### 1.4 Insert writeup of overall replication project goals and big picture thinking (2-3 paragraphs).  \n",
    "* Why do we care about this? \n",
    "* What would the benefit of predicting utilization be? \n",
    "* What might occur if there are errors?\n",
    "* Who are the affected parties and stakeholders?\n",
    "* Other thoughts?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd7569b-9388-4939-9422-6d134dbc0303",
   "metadata": {},
   "source": [
    "**Write up here:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f776c5-8ed6-49c3-9f12-f2afed0605d4",
   "metadata": {},
   "source": [
    "---\n",
    "End of Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f1413d0",
   "metadata": {},
   "source": [
    "### [2.](#Table-of-Contents) Exploratory Data Analysis (EDA)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c4a57f-abcf-47c6-961e-baec728e930a",
   "metadata": {},
   "source": [
    "The specific data used is the [2015 Full Year Consolidated Data File](https://meps.ahrq.gov/mepsweb/data_stats/download_data_files_detail.jsp?cboPufNumber=HC-181) as well as the [2016 Full Year Consolidated Data File](https://meps.ahrq.gov/mepsweb/data_stats/download_data_files_detail.jsp?cboPufNumber=HC-192).\n",
    "\n",
    "* The 2015 file contains data from rounds 3,4,5 of panel 19 (2014) and rounds 1,2,3 of panel 20 (2015). \n",
    "* The 2016 file contains data from rounds 3,4,5 of panel 20 (2015) and rounds 1,2,3 of panel 21 (2016).\n",
    "\n",
    "In this example, three datasets were constructed: one from panel 19, round 5 (used for learning models), one from panel 20, round 3 (used for deployment/testing of model - steps); the other from panel 21, round 3 (used for re-training and deployment/testing of updated model).\n",
    "\n",
    "See the corresponding [Codebook](https://meps.ahrq.gov/mepsweb/data_stats/download_data_files_detail.jsp?cboPufNumber=HC-181) for information on variables.\n",
    "\n",
    "##### Key MEPS dataset features include:\n",
    "* **Utilization**: To measure utilization, a composite feature, 'UTILIZATION', was created to measure the total number of trips requiring some sort of medical care by summing up the following features: OBTOTV15(16), the number of office based visits;  OPTOTV15(16), the number of outpatient visits; ERTOT15(16), the number of ER visits;  IPNGTD15(16), the number of inpatient nights, and  + HHTOTD16, the number of home health visits.\n",
    "* The model classification task is to predict whether a person would have **'high'** utilization (defined as UTILIZATION >= 10, roughly the average utilization for the considered population). High utilization respondents constituted around 17% of each dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7368b94-7451-4cf1-8a66-229d2a07907d",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 2.0 Pre-processing Scripts (for each Panel)\n",
    "\n",
    "There is currently minimal EDA for this tutorial within IBM AIF360 Medical Expenditure Tutorial. Therefore, we have adapted  utility scripts from IBM AIF360 Tutorial for ease of understanding for how datasets were pre-processed. These will be used primarily for EDA purposes. We will utilize IBM's tutorial for the remainder of the project. We have utilized Pandas for this portion of the project. \n",
    "\n",
    "**Note:** these pre-processing script below are run for each data file, and then filtered for each panel. This was done in order to match subsequent portions of the tutorial, and how train/test/validation datasets were split."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b833fd",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 2.1 Get and Load Dataset, Apply Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd36982c-27bb-4159-9d99-1730c1ca8b6c",
   "metadata": {
    "tags": []
   },
   "source": [
    "**Before Proceeding Ensure You Have:**\n",
    "* Forked the AIF360 R=repository and cloned locally to your disk or virtual machine\n",
    "* Downloaded the `h181.csv` and `h192.csv` data files uploaded [here](https://www.kaggle.com/datasets/nanrahman/mepsdata)\n",
    "* Place the `h181.csv` and `h192.csv` in a folder you can access (we placed it in `../aif360/data/raw/meps/` of our forked AIF360 repository)\n",
    "* For EDA we only focus on `h181.csv` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b887ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import sys\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from IPython.display import Markdown, display\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# Datasets\n",
    "from aif360.datasets import MEPSDataset19\n",
    "from aif360.datasets import MEPSDataset20\n",
    "from aif360.datasets import MEPSDataset21\n",
    "\n",
    "# Fairness metrics\n",
    "from aif360.metrics import BinaryLabelDatasetMetric\n",
    "from aif360.metrics import ClassificationMetric\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98db0e2c-0708-42c4-a854-3c074c893a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_181 = pd.read_csv('../aif360/data/raw/meps/h181.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9365299c-679b-4022-93fe-de6017aec710",
   "metadata": {},
   "source": [
    "#### Apply pre-processing scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cbeb4dd-572c-4365-b137-d3b6b4121e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_mappings = {\n",
    "    'label_maps': [{1.0: '>= 10 Visits', 0.0: '< 10 Visits'}],\n",
    "    'protected_attribute_maps': [{1.0: 'White', 0.0: 'Non-White'}]}\n",
    "\n",
    "def default_preprocessing19(df):\n",
    "    \"\"\"\n",
    "    1.Create a new column, RACE that is 'White' if RACEV2X = 1 and HISPANX = 2 i.e. non Hispanic White\n",
    "      and 'non-White' otherwise\n",
    "    2. Restrict to Panel 19\n",
    "    3. RENAME all columns that are PANEL/ROUND SPECIFIC\n",
    "    4. Drop rows based on certain values of individual features that correspond to missing/unknown - generally < -1\n",
    "    5. Compute UTILIZATION, binarize it to 0 (< 10) and 1 (>= 10)\n",
    "    \"\"\"\n",
    "    def race(row):\n",
    "        if ((row['HISPANX'] == 2) and (row['RACEV2X'] == 1)):  #non-Hispanic Whites are marked as WHITE; all others as NON-WHITE#return 'White'\n",
    "            return 'Non-White'\n",
    "\n",
    "    df['RACEV2X'] = df.apply(lambda row: race(row), axis=1)\n",
    "    df = df.rename(columns = {'RACEV2X' : 'RACE'})\n",
    "    \n",
    "    df = df[df['PANEL'] == 19]\n",
    "\n",
    "    # RENAME COLUMNS\n",
    "    df = df.rename(columns = {'FTSTU53X' : 'FTSTU', 'ACTDTY53' : 'ACTDTY', 'HONRDC53' : 'HONRDC', 'RTHLTH53' : 'RTHLTH',\n",
    "                              'MNHLTH53' : 'MNHLTH', 'CHBRON53' : 'CHBRON', 'JTPAIN53' : 'JTPAIN', 'PREGNT53' : 'PREGNT',\n",
    "                              'WLKLIM53' : 'WLKLIM', 'ACTLIM53' : 'ACTLIM', 'SOCLIM53' : 'SOCLIM', 'COGLIM53' : 'COGLIM',\n",
    "                              'EMPST53' : 'EMPST', 'REGION53' : 'REGION', 'MARRY53X' : 'MARRY', 'AGE53X' : 'AGE',\n",
    "                              'POVCAT15' : 'POVCAT', 'INSCOV15' : 'INSCOV'})\n",
    "\n",
    "    df = df[df['REGION'] >= 0] # remove values -1\n",
    "    df = df[df['AGE'] >= 0] # remove values -1\n",
    "\n",
    "    df = df[df['MARRY'] >= 0] # remove values -1, -7, -8, -9\n",
    "\n",
    "    df = df[df['ASTHDX'] >= 0] # remove values -1, -7, -8, -9\n",
    "\n",
    "    df = df[(df[['FTSTU','ACTDTY','HONRDC','RTHLTH','MNHLTH','HIBPDX','CHDDX','ANGIDX','EDUCYR','HIDEG',\n",
    "                             'MIDX','OHRTDX','STRKDX','EMPHDX','CHBRON','CHOLDX','CANCERDX','DIABDX',\n",
    "                             'JTPAIN','ARTHDX','ARTHTYPE','ASTHDX','ADHDADDX','PREGNT','WLKLIM',\n",
    "                             'ACTLIM','SOCLIM','COGLIM','DFHEAR42','DFSEE42','ADSMOK42',\n",
    "                             'PHQ242','EMPST','POVCAT','INSCOV']] >= -1).all(1)]  #for all other categorical features, remove values < -1\n",
    "\n",
    "    def utilization(row):\n",
    "        return row['OBTOTV15'] + row['OPTOTV15'] + row['ERTOT15'] + row['IPNGTD15'] + row['HHTOTD15']\n",
    "\n",
    "    df['TOTEXP15'] = df.apply(lambda row: utilization(row), axis=1)\n",
    "    lessE = df['TOTEXP15'] < 10.0\n",
    "    df.loc[lessE,'TOTEXP15'] = 0.0\n",
    "    moreE = df['TOTEXP15'] >= 10.0\n",
    "    df.loc[moreE,'TOTEXP15'] = 1.0\n",
    "\n",
    "    df = df.rename(columns = {'TOTEXP15' : 'UTILIZATION'})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55df0a46-3c8d-4359-a955-43aff0a118eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def default_preprocessing20(df):\n",
    "    \"\"\"\n",
    "    1.Create a new column, RACE that is 'White' if RACEV2X = 1 and HISPANX = 2 i.e. non Hispanic White\n",
    "      and 'non-White' otherwise\n",
    "    2. Restrict to Panel 20\n",
    "    3. RENAME all columns that are PANEL/ROUND SPECIFIC\n",
    "    4. Drop rows based on certain values of individual features that correspond to missing/unknown - generally < -1\n",
    "    5. Compute UTILIZATION, binarize it to 0 (< 10) and 1 (>= 10)\n",
    "    \"\"\"\n",
    "    def race(row):\n",
    "        if ((row['HISPANX'] == 2) and (row['RACEV2X'] == 1)):  #non-Hispanic Whites are marked as WHITE; all others as NON-WHITE\n",
    "            return 'White'\n",
    "        return 'Non-White'\n",
    "\n",
    "    df['RACEV2X'] = df.apply(lambda row: race(row), axis=1)\n",
    "    df = df.rename(columns = {'RACEV2X' : 'RACE'})\n",
    "\n",
    "    df = df[df['PANEL'] == 20]\n",
    "\n",
    "    # RENAME COLUMNS\n",
    "    df = df.rename(columns = {'FTSTU53X' : 'FTSTU', 'ACTDTY53' : 'ACTDTY', 'HONRDC53' : 'HONRDC', 'RTHLTH53' : 'RTHLTH',\n",
    "                              'MNHLTH53' : 'MNHLTH', 'CHBRON53' : 'CHBRON', 'JTPAIN53' : 'JTPAIN', 'PREGNT53' : 'PREGNT',\n",
    "                              'WLKLIM53' : 'WLKLIM', 'ACTLIM53' : 'ACTLIM', 'SOCLIM53' : 'SOCLIM', 'COGLIM53' : 'COGLIM',\n",
    "                              'EMPST53' : 'EMPST', 'REGION53' : 'REGION', 'MARRY53X' : 'MARRY', 'AGE53X' : 'AGE',\n",
    "                              'POVCAT15' : 'POVCAT', 'INSCOV15' : 'INSCOV'})\n",
    "\n",
    "    df = df[df['REGION'] >= 0] # remove values -1\n",
    "    df = df[df['AGE'] >= 0] # remove values -1\n",
    "\n",
    "    df = df[df['MARRY'] >= 0] # remove values -1, -7, -8, -9\n",
    "\n",
    "    df = df[df['ASTHDX'] >= 0] # remove values -1, -7, -8, -9\n",
    "\n",
    "    df = df[(df[['FTSTU','ACTDTY','HONRDC','RTHLTH','MNHLTH','HIBPDX','CHDDX','ANGIDX','EDUCYR','HIDEG',\n",
    "                             'MIDX','OHRTDX','STRKDX','EMPHDX','CHBRON','CHOLDX','CANCERDX','DIABDX',\n",
    "                             'JTPAIN','ARTHDX','ARTHTYPE','ASTHDX','ADHDADDX','PREGNT','WLKLIM',\n",
    "                             'ACTLIM','SOCLIM','COGLIM','DFHEAR42','DFSEE42','ADSMOK42',\n",
    "                             'PHQ242','EMPST','POVCAT','INSCOV']] >= -1).all(1)]  #for all other categorical features, remove values < -1\n",
    "\n",
    "    def utilization(row):\n",
    "        return row['OBTOTV15'] + row['OPTOTV15'] + row['ERTOT15'] + row['IPNGTD15'] + row['HHTOTD15']\n",
    "\n",
    "    df['TOTEXP15'] = df.apply(lambda row: utilization(row), axis=1)\n",
    "    lessE = df['TOTEXP15'] < 10.0\n",
    "    df.loc[lessE,'TOTEXP15'] = 0.0\n",
    "    moreE = df['TOTEXP15'] >= 10.0\n",
    "    df.loc[moreE,'TOTEXP15'] = 1.0\n",
    "\n",
    "    df = df.rename(columns = {'TOTEXP15' : 'UTILIZATION'})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c23a2c-9148-466c-8400-64f425d2e53f",
   "metadata": {},
   "source": [
    "#### Taken from pre-processing scripts to retain same columns used in model development for tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c6d234-d213-4bda-96c2-e11605af0526",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_name='UTILIZATION'\n",
    "favorable_classes=[1.0]\n",
    "protected_attribute_names=['RACE']\n",
    "privileged_classes=[['White']]\n",
    "instance_weights_name='PERWT15F'\n",
    "categorical_features=['REGION','SEX','MARRY',\n",
    "                                 'FTSTU','ACTDTY','HONRDC','RTHLTH','MNHLTH','HIBPDX','CHDDX','ANGIDX',\n",
    "                                 'MIDX','OHRTDX','STRKDX','EMPHDX','CHBRON','CHOLDX','CANCERDX','DIABDX',\n",
    "                                 'JTPAIN','ARTHDX','ARTHTYPE','ASTHDX','ADHDADDX','PREGNT','WLKLIM',\n",
    "                                 'ACTLIM','SOCLIM','COGLIM','DFHEAR42','DFSEE42', 'ADSMOK42', 'PHQ242',\n",
    "                                 'EMPST','POVCAT','INSCOV']\n",
    "\n",
    "features_to_keep=['REGION','AGE','SEX','RACE','MARRY',\n",
    "                                 'FTSTU','ACTDTY','HONRDC','RTHLTH','MNHLTH','HIBPDX','CHDDX','ANGIDX',\n",
    "                                 'MIDX','OHRTDX','STRKDX','EMPHDX','CHBRON','CHOLDX','CANCERDX','DIABDX',\n",
    "                                 'JTPAIN','ARTHDX','ARTHTYPE','ASTHDX','ADHDADDX','PREGNT','WLKLIM',\n",
    "                                 'ACTLIM','SOCLIM','COGLIM','DFHEAR42','DFSEE42', 'ADSMOK42',\n",
    "                                 'PCS42','MCS42','K6SUM42','PHQ242','EMPST','POVCAT','INSCOV','UTILIZATION', 'PERWT15F']\n",
    "features_to_drop=[]\n",
    "na_values=[]\n",
    "# custom_preprocessing=default_preprocessing <- don't need this yet for EDA\n",
    "metadata=default_mappings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c2e7d5-b7b6-4af2-a067-25a1102f1e1b",
   "metadata": {},
   "source": [
    "We encourage you to search through the repository and take a look at these scripts, \n",
    "they can be found in `../aif360/dataset/` in your forked AIF360 repository:\n",
    "* AIF360/aif360/datasets/meps_dataset_panel19_fy2015.py\n",
    "* AIF360/aif360/datasets/meps_dataset_panel20_fy2015.py\n",
    "\n",
    "To Explore the `Utilization` and `RACE` features, and the variables used to impute these features:\n",
    "* See the corresponding [HC 181 Codebook](https://meps.ahrq.gov/mepsweb/data_stats/download_data_files_detail.jsp?cboPufNumber=HC-181) for information on variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc7d333-0247-4e92-a550-5f28a6739752",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_panel_19 = default_preprocessing19(raw_181)\n",
    "df_panel_19_reduced = df_panel_19[features_to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2602e0e-e24e-4362-b378-6a1d2b24baff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_panel_20 = default_preprocessing20(raw_181)\n",
    "df_panel_20_reduced = df_panel_20[features_to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ccad607-d831-432b-b182-14dddc959a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### END OF PRE-PROCRESSING ####"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e18fec6",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 2.2 Data shape and features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16e7d10-db43-4bfb-b8b5-14d79da573f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_panel_19_reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e602c93-d281-4821-8b1c-67125238a1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_panel_20_reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5977a351",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify feature names\n",
    "# Check for categorical features\n",
    "# Summary statistics\n",
    "# Shapes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55329591-7a00-4b97-8422-29bb20c55966",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 2.3 Outlier Detection and Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104ba0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Null handling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c4b75c-3f0b-4383-9607-758d52283321",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 2.4 Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59cf08f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preliminary data visualizations\n",
    "# Correlation plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e4cb401-c3fa-4916-b71b-5e72c03227c7",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 2.5 Other analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b15f3b9-126d-490a-9e29-94ef231a4475",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a37cb445-33ef-4b4e-8079-e7d46e6fbb72",
   "metadata": {},
   "source": [
    "-----\n",
    "End of Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90379749-ae30-4908-b400-400254239ecd",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3604122-a08a-4cf2-b1a7-66e678666909",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb5e270-5781-4e88-a180-4de7660a1c92",
   "metadata": {},
   "source": [
    "_Items below will be updated as course progress_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da83c738",
   "metadata": {},
   "source": [
    "### [3.](#Table-of-Contents) Model Development "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a9d0791",
   "metadata": {},
   "source": [
    "### [4.](#Table-of-Contents) Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b3e294",
   "metadata": {},
   "source": [
    "### [5.](#Table-of-Contents) Bias Mitigation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "106d7b57",
   "metadata": {},
   "source": [
    "### [6.](#Table-of-Contents) Results Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61997b93",
   "metadata": {},
   "source": [
    "### [7.](#Table-of-Contents) Explainability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9010ecc",
   "metadata": {},
   "source": [
    "### [8.](#Table-of-Contents) Conclusion & Discussion"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
